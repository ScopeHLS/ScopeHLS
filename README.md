# Scope HLS Project

This repo contains the codes for building Scope HLS, an automated framework to be trained to act as the surrogate of the HLS tool. It can be used to expedite the design optimization process. The database used in this repo is built using the AMD/Xilinx HLS tools, but can be replaced by other databases. 

ScopeHLS is a scope-aware pragma learning framework for efficient design space exploration (DSE) in FPGA high-level synthesis (HLS). Unlike prior methods that treat compiler pragmas as regular tokens, ScopeHLS explicitly models the structured interaction between pragmas and source code using a scope-aware cross-attention mechanism. This enables the model to learn how optimization directives affect hardware behavior at a fine-grained level. To enhance generalization under data scarcity and domain shift, ScopeHLS adopts a three-stage training pipeline including large-scale pretraining, scoped fine-tuning, and task-specific adaptation. These innovations lead to significantly improved prediction accuracy, faster inference speed, and better transferability to unseen HLS designs. ScopeHLS offers an interpretable and practical solution for learning-based HLS optimization.

## Previous Work

You can visit the following links to view previous representative research works:  
- GNN-DSE DAC'22 paper: "Automated Accelerator Optimization Aided by Graph Neural Networks" 
- HARP ICCAD'23 Best Paper Award candidate: Robust GNN-based Representation Learning for HLS
- ProgSG Cross-Modality Program Representation Learning for Electronic Design Automation with High-Level Synthesis
- HLSyn NeurIPS'24 HLSyn benchmark for paper "Towards a Comprehensive Benchmark for FPGA Targeted High-Level Synthesis"
- HierarchicalMoE AAAI'25 Paper: Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis

## Content
1. [Requirements and Dependencies](#requirements-and-dependencies)
2. [Project File Tree](#project-file-tree)
3. [Running the Project](#running-the-project)

## Requirements and Dependencies

### Requirements
You can install the required packages for running this project using:

````bash
conda create --name ScopeHLS python=3.10
conda activate ScopeHLS

pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url XXX
pip install -r requirements.txt
````

### Database Generation
The initial database is generated by AutoDSE which is built on top of the Merlin Compiler. If you want to expand the database, please consider installing them.You can try to get the NeurIPS'24 dataset

For synthesizing the designs, three versions of the AMD/Xilinx HLS tools have been used, SDAccel 2018.3 (denoted with `v18`), Vitis 2020.2 (denoted with `v20`), and Vitis 2021.1 (denoted with `v21`).

## Project File Tree
The project file structure is as below:

````
.
+-- code              # Contains the main source code for the project, including scripts for training, inference, and design space exploration.
    +-- config        # Holds configuration files and parameters for customizing the project's behavior.
    +-- dataset       # Includes scripts and utilities for dataset preprocessing and management.
    +-- model         # Contains model definitions and related utilities for ScopeHLS.
    +-- train         # Includes training scripts and resources for model optimization.
    main.py           # The main entry point for running the project.

+-- data              # Stores input data, intermediate results, and output files generated during execution.
+-- encoder_codet5    # Contains the implementation of the CodeT5 encoder used in the project.
+-- models            # Includes pre-trained models and checkpoints for ScopeHLS.     
````

## Running the Project

The `code/config.py` contains all the tunable parameters of the project. If you want to change the modes of running, please edit this file or YAML.

After setting the configurations, run the following command to execute the project:

````bash
cd code
python pre_demo.py
python main.py
````
You can run the `src/main.py` for training, inference, and design space exploration based on the config YAML.

## Key Configuration Parameters

The following are the **essential configuration parameters** for training and inference in ScopeHLS. Full configuration can be found in ./config/test.yaml.

### Paths
- `data_dir`: Path to training dataset  
- `codet5p_path`: Path to pretrained CodeT5 encoder  
- `model_base_dir`: Directory for saving model checkpoints  

### Model Settings
- `t5_dim`: Hidden dimension of CodeT5 encoder (default: `1024`)  
- `hidden_dim`: Hidden dimension for internal layers (default: `64`)  
- `self_n_heads`: Number of self-attention heads (default: `4`)  
- `decoder_layers`: Number of decoder layers (default: `6`)  

### Dataset & Validation
- `validation_ratio`: Ratio of validation data (default: `0.2`)  
- `min_samples_per_group`: Minimum samples per design group (default: `20`)  

### Inference
- `inference_batch_size`: Batch size during inference (default: `64`)  
- `inference_time`: Max inference time in seconds (default: `300`)  

